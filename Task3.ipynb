{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f563bbb-6386-4792-af34-2ca74a2edb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Durga Prasad\\AppData\\Local\\Temp\\ipykernel_24624\\709283959.py\", line 56, in <module>\n",
      "    import nltk\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 38, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Durga Prasad\\AppData\\Local\\Temp\\ipykernel_24624\\709283959.py\", line 56, in <module>\n",
      "    import nltk\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Durga Prasad\\AppData\\Local\\Temp\\ipykernel_24624\\709283959.py\", line 56, in <module>\n",
      "    import nltk\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 52, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Durga Prasad\\AppData\\Local\\Temp\\ipykernel_24624\\709283959.py\", line 56, in <module>\n",
      "    import nltk\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\chunk\\util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\nltk\\classify\\scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 61, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 66, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Durga Prasad\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP Chatbot (NLTK + optional spaCy)\n",
      "Type 'exit' or 'quit' to end.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye! Have a great day.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "NLP Chatbot (NLTK + optional spaCy)\n",
    "===================================\n",
    "A single-file, working chatbot that uses classic NLP techniques to answer user queries.\n",
    "\n",
    "Features\n",
    "--------\n",
    "- Text preprocessing (lowercasing, tokenization, stopword removal, lemmatization)\n",
    "- Intent recognition via TF-IDF + cosine similarity (scikit-learn if available)\n",
    "  * Graceful fallback to keyword scoring when scikit-learn isn't installed.\n",
    "- Small, embedded knowledge base for FAQs\n",
    "- Rule-handled utilities: greetings, goodbye, thanks, time/date, simple calc\n",
    "- Optional Named Entity Recognition (NER) via spaCy if installed (adds entities to responses)\n",
    "- Clear, commented code suitable for coursework submissions\n",
    "\n",
    "Run\n",
    "---\n",
    "1) CLI chatbot (recommended):\n",
    "   python nlp_chatbot.py\n",
    "\n",
    "2) Change configuration (optional):\n",
    "   - Edit INTENTS, KNOWLEDGE_BASE, and THRESHOLDS below.\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "- Python 3.8+\n",
    "- NLTK (recommended)\n",
    "  pip install nltk\n",
    "  (The script tries to auto-download 'punkt', 'wordnet', 'omw-1.4', 'stopwords' if missing.\n",
    "   If your environment blocks downloads, it will still run with simpler tokenization.)\n",
    "- scikit-learn (optional, for TF-IDF):\n",
    "  pip install scikit-learn\n",
    "- spaCy (optional, for NER):\n",
    "  pip install spacy\n",
    "  python -m spacy download en_core_web_sm\n",
    "\n",
    "Notes\n",
    "-----\n",
    "This is not a generative LLM; it's a classic retrieval/rule-based chatbot—perfect for demonstrating NLP fundamentals.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import datetime as dt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# -------------------- Optional imports with graceful fallback --------------------\n",
    "# NLTK (preferred)\n",
    "nltk_available = True\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "except Exception:\n",
    "    nltk_available = False\n",
    "\n",
    "# scikit-learn (for TF-IDF)\n",
    "sklearn_available = True\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "except Exception:\n",
    "    sklearn_available = False\n",
    "\n",
    "# spaCy (optional NER)\n",
    "spacy_nlp = None\n",
    "try:\n",
    "    import spacy\n",
    "    try:\n",
    "        spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except Exception:\n",
    "        spacy_nlp = None\n",
    "except Exception:\n",
    "    spacy_nlp = None\n",
    "\n",
    "# -------------------- Data: intents + knowledge base --------------------\n",
    "\n",
    "INTENTS: List[Dict] = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\n",
    "            \"hello\", \"hi\", \"hey\", \"good morning\", \"good afternoon\", \"good evening\",\n",
    "            \"yo\", \"howdy\", \"namaste\", \"hola\"\n",
    "        ],\n",
    "        \"responses\": [\n",
    "            \"Hello! How can I help you today?\",\n",
    "            \"Hi there! What can I do for you?\",\n",
    "            \"Hey! Ask me anything.\"\n",
    "        ],\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"bye\", \"goodbye\", \"see you\", \"catch you later\", \"quit\", \"exit\"],\n",
    "        \"responses\": [\n",
    "            \"Goodbye! Have a great day.\",\n",
    "            \"See you later!\",\n",
    "            \"Bye! Come back anytime.\"\n",
    "        ],\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"thanks\", \"thank you\", \"ty\", \"thx\", \"appreciate it\"],\n",
    "        \"responses\": [\n",
    "            \"You're welcome!\",\n",
    "            \"Anytime!\",\n",
    "            \"Glad I could help.\"\n",
    "        ],\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"time\",\n",
    "        \"patterns\": [\"what time is it\", \"current time\", \"tell me the time\", \"time now\"],\n",
    "        \"responses\": [],  # handled dynamically\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"date\",\n",
    "        \"patterns\": [\"what's the date\", \"today's date\", \"date today\"],\n",
    "        \"responses\": [],  # handled dynamically\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"calc\",\n",
    "        \"patterns\": [\"calculate\", \"compute\", \"solve\", \"what is\", \"evaluate\"],\n",
    "        \"responses\": [],  # handled dynamically by parsing an expression\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"help\",\n",
    "        \"patterns\": [\"help\", \"what can you do\", \"commands\", \"how to use\"],\n",
    "        \"responses\": [\n",
    "            \"I can handle greetings, time/date, simple calculations, and FAQs.\\n\"\n",
    "            \"Try: 'what time is it', 'what is 22/7', or ask about the topics I know.\"\n",
    "        ],\n",
    "        \"context_set\": \"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Simple, embedded FAQ knowledge base\n",
    "KNOWLEDGE_BASE: Dict[str, str] = {\n",
    "    \"what is nlp\": \"NLP (Natural Language Processing) is a field of AI focused on enabling computers to understand and generate human language.\",\n",
    "    \"what is nltk\": \"NLTK is a leading Python library for working with human language data—tokenization, stemming, tagging, parsing, and more.\",\n",
    "    \"what is spacy\": \"spaCy is a modern NLP library offering fast tokenization, POS tagging, NER, and other pipelines optimized for production.\",\n",
    "    \"difference between nltk and spacy\": \"NLTK is great for education and research with many resources; spaCy focuses on production performance and modern pipelines (like efficient NER).\",\n",
    "    \"what is tfidf\": \"TF-IDF (Term Frequency–Inverse Document Frequency) scores words by how important they are to a document within a corpus.\",\n",
    "    \"who created you\": \"I was created as a demo chatbot using Python and classic NLP techniques.\",\n",
    "    \"what can you do\": \"I can answer FAQs, tell time/date, do simple calculations, and show extracted entities if spaCy is available.\"\n",
    "}\n",
    "\n",
    "# Similarity thresholds\n",
    "THRESHOLDS = {\n",
    "    \"intent_confidence\": 0.35,  # min score to accept an intent via TF-IDF\n",
    "    \"faq_confidence\": 0.25,     # min score to answer from FAQ via TF-IDF\n",
    "}\n",
    "\n",
    "# -------------------- NLP utilities --------------------\n",
    "\n",
    "_STOPWORDS = set()\n",
    "_LEMMA = None\n",
    "def _setup_nltk():\n",
    "    global _STOPWORDS, _LEMMA, nltk_available\n",
    "    if not nltk_available:\n",
    "        return\n",
    "\n",
    "    # Try to download resources if missing; if fails, we proceed with fallbacks.\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt\")\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download(\"punkt\", quiet=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        nltk.data.find(\"corpora/stopwords\")\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download(\"stopwords\", quiet=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        nltk.data.find(\"corpora/wordnet\")\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download(\"wordnet\", quiet=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        nltk.data.find(\"corpora/omw-1.4\")\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download(\"omw-1.4\", quiet=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        _STOPWORDS = set(stopwords.words(\"english\"))\n",
    "    except Exception:\n",
    "        _STOPWORDS = set()\n",
    "\n",
    "    try:\n",
    "        _LEMMA = WordNetLemmatizer()\n",
    "    except Exception:\n",
    "        _LEMMA = None\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower().strip()\n",
    "    # Remove punctuation except math symbols for calc\n",
    "    cleaned = re.sub(r\"[^\\w\\s\\.\\+\\-\\*\\/\\(\\)%]\", \" \", text)\n",
    "    if nltk_available:\n",
    "        try:\n",
    "            from nltk.tokenize import word_tokenize\n",
    "            return [t for t in word_tokenize(cleaned) if t.strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Fallback: simple split\n",
    "    return [t for t in cleaned.split() if t.strip()]\n",
    "\n",
    "def normalize(tokens: List[str]) -> List[str]:\n",
    "    if not tokens:\n",
    "        return tokens\n",
    "    # Remove stopwords and lemmatize\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        if t in _STOPWORDS:\n",
    "            continue\n",
    "        if _LEMMA:\n",
    "            try:\n",
    "                t = _LEMMA.lemmatize(t)\n",
    "            except Exception:\n",
    "                pass\n",
    "        out.append(t)\n",
    "    return out\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    return \" \".join(normalize(tokenize(text)))\n",
    "\n",
    "# -------------------- TF-IDF pipeline (with fallback) --------------------\n",
    "\n",
    "class IntentMatcher:\n",
    "    def __init__(self, intents: List[Dict]):\n",
    "        self.intents = intents\n",
    "        self.use_sklearn = sklearn_available\n",
    "        self.tags: List[str] = []\n",
    "        self.pattern_texts: List[str] = []\n",
    "\n",
    "        for intent in intents:\n",
    "            tag = intent[\"tag\"]\n",
    "            patterns = intent.get(\"patterns\", [])\n",
    "            for p in patterns:\n",
    "                self.tags.append(tag)\n",
    "                self.pattern_texts.append(preprocess(p))\n",
    "\n",
    "        if self.use_sklearn and self.pattern_texts:\n",
    "            self.vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "            self.tfidf = self.vectorizer.fit_transform(self.pattern_texts)\n",
    "        else:\n",
    "            self.vectorizer = None\n",
    "            self.tfidf = None\n",
    "\n",
    "    def match(self, user_text: str) -> Tuple[Optional[str], float]:\n",
    "        query = preprocess(user_text)\n",
    "        if not query:\n",
    "            return None, 0.0\n",
    "\n",
    "        if self.use_sklearn and self.vectorizer is not None:\n",
    "            q_vec = self.vectorizer.transform([query])\n",
    "            sims = cosine_similarity(q_vec, self.tfidf)[0]\n",
    "            if len(sims) == 0:\n",
    "                return None, 0.0\n",
    "            idx = int(sims.argmax())\n",
    "            return self.tags[idx], float(sims[idx])\n",
    "\n",
    "        # Fallback: simple keyword overlap scoring\n",
    "        q_tokens = set(query.split())\n",
    "        best_tag, best_score = None, 0.0\n",
    "        for tag, pattern in zip(self.tags, self.pattern_texts):\n",
    "            p_tokens = set(pattern.split())\n",
    "            score = len(q_tokens & p_tokens) / (len(q_tokens) + 1e-9)\n",
    "            if score > best_score:\n",
    "                best_score, best_tag = score, tag\n",
    "        return best_tag, best_score\n",
    "\n",
    "class FAQMatcher:\n",
    "    def __init__(self, kb: Dict[str, str]):\n",
    "        self.kb = kb\n",
    "        self.keys = list(kb.keys())\n",
    "        self.use_sklearn = sklearn_available and len(self.keys) > 0\n",
    "        if self.use_sklearn:\n",
    "            self.vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "            self.tfidf = self.vectorizer.fit_transform([preprocess(k) for k in self.keys])\n",
    "        else:\n",
    "            self.vectorizer = None\n",
    "            self.tfidf = None\n",
    "\n",
    "    def best_answer(self, user_text: str) -> Tuple[Optional[str], float]:\n",
    "        query = preprocess(user_text)\n",
    "        if not query:\n",
    "            return None, 0.0\n",
    "\n",
    "        if self.use_sklearn and self.vectorizer is not None:\n",
    "            q_vec = self.vectorizer.transform([query])\n",
    "            sims = cosine_similarity(q_vec, self.tfidf)[0]\n",
    "            if len(sims) == 0:\n",
    "                return None, 0.0\n",
    "            idx = int(sims.argmax())\n",
    "            key = self.keys[idx]\n",
    "            return self.kb[key], float(sims[idx])\n",
    "\n",
    "        # Fallback: keyword overlap\n",
    "        q_tokens = set(query.split())\n",
    "        best_key, best_score = None, 0.0\n",
    "        for key in self.keys:\n",
    "            k_tokens = set(preprocess(key).split())\n",
    "            score = len(q_tokens & k_tokens) / (len(q_tokens) + 1e-9)\n",
    "            if score > best_score:\n",
    "                best_score, best_key = score, key\n",
    "        return (self.kb[best_key] if best_key else None), best_score\n",
    "\n",
    "# -------------------- Core chatbot --------------------\n",
    "\n",
    "class NLPChatbot:\n",
    "    def __init__(self,\n",
    "                 intents: List[Dict],\n",
    "                 knowledge_base: Dict[str, str],\n",
    "                 thresholds: Dict[str, float]):\n",
    "        _setup_nltk()\n",
    "        self.intents = intents\n",
    "        self.kb = knowledge_base\n",
    "        self.thresholds = thresholds\n",
    "        self.intent_matcher = IntentMatcher(intents)\n",
    "        self.faq_matcher = FAQMatcher(knowledge_base)\n",
    "\n",
    "    def respond(self, message: str) -> str:\n",
    "        if not message or not message.strip():\n",
    "            return \"I didn't catch that. Could you rephrase?\"\n",
    "\n",
    "        # Try intent detection\n",
    "        tag, score = self.intent_matcher.match(message)\n",
    "        if tag and score >= self.thresholds[\"intent_confidence\"]:\n",
    "            resp = self._handle_intent(tag, message)\n",
    "            if resp:\n",
    "                return self._maybe_add_entities(message, resp)\n",
    "\n",
    "        # Try FAQ retrieval\n",
    "        answer, faq_score = self.faq_matcher.best_answer(message)\n",
    "        if answer and faq_score >= self.thresholds[\"faq_confidence\"]:\n",
    "            return self._maybe_add_entities(message, answer)\n",
    "\n",
    "        # Fallback\n",
    "        return (\"I'm not sure about that yet. Try asking in a different way, \"\n",
    "                \"or type 'help' to see what I can do.\")\n",
    "\n",
    "    def _handle_intent(self, tag: str, message: str) -> Optional[str]:\n",
    "        if tag == \"greeting\":\n",
    "            return self._pick_response(tag)\n",
    "        if tag == \"goodbye\":\n",
    "            return self._pick_response(tag)\n",
    "        if tag == \"thanks\":\n",
    "            return self._pick_response(tag)\n",
    "        if tag == \"help\":\n",
    "            return self._pick_response(tag)\n",
    "        if tag == \"time\":\n",
    "            now = dt.datetime.now().strftime(\"%H:%M:%S\")\n",
    "            return f\"The current time is {now}.\"\n",
    "        if tag == \"date\":\n",
    "            today = dt.date.today().strftime(\"%A, %B %d, %Y\")\n",
    "            return f\"Today is {today}.\"\n",
    "        if tag == \"calc\":\n",
    "            result = self._safe_calculate(message)\n",
    "            return result\n",
    "        # default\n",
    "        return self._pick_response(tag)\n",
    "\n",
    "        # Note: FAQ handled separately\n",
    "\n",
    "    def _pick_response(self, tag: str) -> str:\n",
    "        for it in self.intents:\n",
    "            if it[\"tag\"] == tag:\n",
    "                rs = it.get(\"responses\", [])\n",
    "                if rs:\n",
    "                    import random\n",
    "                    return random.choice(rs)\n",
    "        return \"\"\n",
    "\n",
    "    def _safe_calculate(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Evaluate simple arithmetic expressions safely.\n",
    "        Allowed: numbers, + - * / % ( )\n",
    "        \"\"\"\n",
    "        expr = self._extract_expression(text)\n",
    "        if not expr:\n",
    "            return \"Please provide an expression, e.g., 'what is (2+3)*4'.\"\n",
    "        if not re.fullmatch(r\"[0-9\\.\\+\\-\\*\\/%\\(\\)\\s]+\", expr):\n",
    "            return \"Sorry, I only support basic arithmetic (+, -, *, /, %, parentheses).\"\n",
    "\n",
    "        try:\n",
    "            # Very restricted eval: use Python's eval with empty globals/locals\n",
    "            result = eval(expr, {\"__builtins__\": {}}, {})\n",
    "            return f\"{expr.strip()} = {result}\"\n",
    "        except ZeroDivisionError:\n",
    "            return \"Division by zero is undefined.\"\n",
    "        except Exception:\n",
    "            return \"I couldn't evaluate that. Check the expression and try again.\"\n",
    "\n",
    "    def _extract_expression(self, text: str) -> Optional[str]:\n",
    "        # Try to find the longest arithmetic-looking substring\n",
    "        candidates = re.findall(r\"([0-9\\.\\+\\-\\*\\/%\\(\\)\\s]{3,})\", text)\n",
    "        if not candidates:\n",
    "            return None\n",
    "        # Pick the longest\n",
    "        return max(candidates, key=len)\n",
    "\n",
    "    def _maybe_add_entities(self, user_text: str, response: str) -> str:\n",
    "        if spacy_nlp is None:\n",
    "            return response\n",
    "        try:\n",
    "            doc = spacy_nlp(user_text)\n",
    "            ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "            if ents:\n",
    "                ent_strs = [f\"{t} ({l})\" for t, l in ents]\n",
    "                response += \"\\n\\n[Detected entities: \" + \", \".join(ent_strs) + \"]\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        return response\n",
    "\n",
    "# -------------------- CLI loop --------------------\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"NLP Chatbot (NLTK + optional spaCy)\")\n",
    "    print(\"Type 'exit' or 'quit' to end.\\n\")\n",
    "    bot = NLPChatbot(INTENTS, KNOWLEDGE_BASE, THRESHOLDS)\n",
    "    while True:\n",
    "        try:\n",
    "            user = input(\"You: \").strip()\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nBot: Goodbye!\")\n",
    "            break\n",
    "        if not user:\n",
    "            print(\"Bot: I didn't catch that. Could you rephrase?\")\n",
    "            continue\n",
    "        if user.lower() in {\"exit\", \"quit\", \"bye\"}:\n",
    "            print(\"Bot:\", bot.respond(\"bye\"))\n",
    "            break\n",
    "        reply = bot.respond(user)\n",
    "        print(\"Bot:\", reply)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa0f19-321b-4f83-95fb-938643fd6f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
